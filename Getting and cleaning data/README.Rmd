---
title: "Getting and Cleaning Data Course Project"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

The code is intended to run without any modification. The data that is used for the project is downloaded on the default directory, then unzipped. 
After the project is done, the produced zip, directory and files are deleted.  
The scripts can be found here <https://github.com/theoser2/datasciencecoursera/tree/master/Getting%20and%20cleaning%20data>.

## 0. Download, extract and load the data sets.

### Download
Before even thinking of merging the datasets, I first need to download the zip file and extract it. In order to make the code able to run anywhere, I will use the default user directory "~".
```{r eval=F, echo=T}
setwd("~")
if(file.exists("data_coursera.zip")) file.remove("data_coursera.zip")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip", destfile="data_coursera.zip")
```

### Extract
Now that I downloaded the file, I unzip it and move to the newly created directory "UCI HAR Dataset", that will be the main directory in the following.
```{r eval=F, echo=T}
unzip("data_coursera.zip")
setwd("UCI HAR Dataset")
```

### Load
These datasets are located into two sub-directories: test and train. They are in txt structured format and therefore a simple read.table() does the job. Currently, we do not pay attention to variable names but we know they are located in a separate "feature.txt" at the main directory.
```{r eval=F, echo=T}
test_X_set <- read.table("test/X_test.txt", dec=".", header=F)
test_y_set <- read.table("test/y_test.txt", dec=".", header=F)
test_subject_set <- read.table("test/subject_test.txt", dec=".", header=F)

train_X_set <- read.table("train/X_train.txt", dec=".", header=F)
train_y_set <- read.table("train/y_train.txt", dec=".", header=F)
train_subject_set <- read.table("train/subject_train.txt", dec=".", header=F)
```
For both train and test data sets: 
* X_set contains 561 variables calculated from original accelerometer data.
* y_set contains the activity label (corresponding activity names are in the "activity_labels.txt" file)
* subject_set contains the number of the subject.

## 1. Merges the training and the test sets to create one data set.
As all variables are exactly in the same order, I simply need to use a rbind function to merge them. 
```{r eval=F, echo=T}
X_set <- rbind(train_X_set, test_X_set)
y_set <- rbind(train_y_set, test_y_set)
subject_set <- rbind(train_subject_set, test_subject_set)
```
Also, I merge X_set and subject_set as the subjects will be usefull in question 5.
```{r eval=F, echo=T}
X_set <- X_set %>% mutate(subject = subject_set$V1)
```

## 2. Extracts only the measurements on the mean and standard deviation for each measurement.
Using the table "feature.txt" in the main directory, I select the variables to extract with a regular expression filter. This produces a vector "to_extract" of the columns numbers to keep.
Then, I extract these columns using the previous vector and also the last column that was the subject numbers (for Question 5). 
```{r eval=F, echo=T}
features <- read.table("features.txt", dec=".", header=F)
to_extract <- grep("mean|std", as.character(features$V2))
X_set_filt <- X_set[,c(to_extract, ncol(X_set))]
```

## 3.Uses descriptive activity names to name the activities in the data set.
Here I load the activity labels from the "activity_labels.txt" file, then I join it to the y_set data. This gives me a data.frame of the names corresponding to the X_set_filt data.frame activity names. 
```{r eval=F, echo=T}
activities <- read.table("activity_labels.txt", header=F, stringsAsFactors = F)
activities_set <- y_set %>% left_join(activities, by="V1") # Left join to keep the order of y_set
X_set_filt <- X_set_filt %>% mutate(activities = as.character(activities_set$V2))
head(X_set_filt) # Checking activites are added
```


## 4. Appropriately labels the data set with descriptive variable names.
```{r eval=F, echo=T}
names(X_set_filt)[1:79] <- as.character(features$V2[to_extract])
```


## 5. From the data set in step 4:
### creates a second, independent tidy data set with the average of each variable for each activity and each subject.
Here I simply group the X_set_filt on the subject an activities columns before applying the average of all the other variables. 
```{r eval=F, echo=T}
X_set_summary <- X_set_filt %>% group_by(subject, activities) %>% summarize_each(funs(mean))
```

## Conclusion
We also remove all the data, the zip downloaded and the directory created if you want to test it on your computer. 
```{r eval=F, echo=T}
rm(list=ls(all=TRUE)) # Be careful with this instruction, delete everything in R workspace
gc()
file.remove("data_coursera.zip")
unlink("UCI HAR Dataset", recursive=T)
```


